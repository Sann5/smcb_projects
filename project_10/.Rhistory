knitr::opts_chunk$set(echo = TRUE)
library("ggplot2")
library("caret")
library("glmnet")
library("pROC")
library("dplyr")
#Read in dataset
set.seed(42)
load("./yeastStorey.rda")
#Sample data
Sampledata<- createDataPartition(data$Marker,p = 0.7,list = FALSE)
#Create training data
Traindata<-data[Sampledata, ]
#Create test data
Testdata<-data[-Sampledata, ]
#Create X and y train
X_train <- apply(as.matrix.noquote(Traindata[,-1]), 2,as.numeric)
Y_train<- Traindata[,1]
#Create X and y test
X_test <- apply(as.matrix.noquote(Testdata[,-1]), 2, as.numeric)
Y_test <- Testdata[,1]
#Get alpha vector  α = {0, 0.1, 0.2, · · · , 1}
alphavec= seq(0, 1, 0.1)
#Get the foldid
foldid <- sample(1:10, size=length(Sampledata), replace = TRUE )
#Find best lambda using 10-fold cross-validation
crossval <- lapply(alphavec, function(n)
{cv.glmnet(X_train, Y_train, alpha=n, family = "binomial",foldid = foldid, type.measure="mse")})
#Make dataset with the new values for plotting
dd<- do.call(rbind,lapply(1:length(alphavec), function(x){
cbind.data.frame(alphavec[x],crossval[[x]]$lambda,crossval[[x]]$cvm)}))
colnames(dd)<- c('alpha','lambda','cvm')
#Predict the response on the test dataset
#Get alpha and lambda
param <- filter(dd ,cvm== min(cvm))
#Fit model using trainingdata
model <-glmnet(X_train, Y_train, alpha = param$alpha, family = "binomial" ,lambda = param$lambda)
#Predict Y of testdata
predY <- predict(model, newx = X_test, type = "class")
#Plot cross-validation error as a function of log
Acc <- roc(Y_test,as.vector(predY))
